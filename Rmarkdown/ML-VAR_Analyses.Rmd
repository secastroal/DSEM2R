---
title: "ML-VAR Analyses"
author:
  - Sebastian Castro-Alvarez
  - Laura F. Bringmann
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  bookdown::word_document2:
    fig_caption: yes
    number_sections: FALSE
    reference_docx: APAtemplate.docx
bibliography: references.bib
csl: apa7.csl
link-citations: true
always_allow_html: true
---
  
```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
library(bookdown)
library(pander)
knitr::opts_chunk$set(echo = TRUE, fig.height = 4, fig.width = 6, fig.pos = "!H",  
                      warning=FALSE, message=FALSE)

panderOptions('table.alignment.default', function(df)
  ifelse(sapply(df, is.numeric), 'right', 'left'))
panderOptions('table.split.table', Inf)
panderOptions('big.mark', ",")
panderOptions('keep.trailing.zeros', TRUE)

# Use this code to render the document:
# Render the document to a .docx file.
# rmarkdown::render("Rmarkdown/ML-VAR_Analyses.Rmd") 
```

In this document, we analyze intensive longitudinal data of emotion dynamics. To analyze these data we use the multilevel-vector autoregressive model (ML-VAR) and the vector autoregressive model (VAR). We also include all R code needed to run and replicate the analyses.

To start, we first load into our R environment all the required R packages:

```{r}
packages <- rownames(installed.packages())
if (!"psych" %in% packages) {install.packages("psych")}
if (!"naniar" %in% packages) {install.packages("naniar")}
if (!"lubridate" %in% packages) {install.packages("lubridate")}
if (!"remotes" %in% packages) {install.packages("remotes")}
if (!"esmpack" %in% packages) {
  remotes::install_github("secastroal/esmpack")
  }
library(esmpack)
library(foreign)
rm(packages)
```

## Data Preprocessing

In this section, we read and clean the data to obtain the final sample that we use for the analyses. 

```{r}
mlvardata <- read.csv2("deid_cleaned_lifepak_ttt_phase_1.csv", 
                       header = TRUE, sep = ",")
```

The data has 14 variables: ID, response number, beep time, response time, time difference (probably how long did it take the person to complete the questionnaire), beep completed (variable indicating that the person 'completed' the questionnaire on that beep), and scores on 6 emotions.

We get a quick summary of the emotion scores as follows:

```{r}
summary(mlvardata[, 7:14])
```

```{r}
mlvardata$notification_time <- as.POSIXct(gsub("T", "", 
                                               mlvardata$notification_time))
mlvardata$response_time     <- as.POSIXct(gsub("T", "",
                                               mlvardata$response_time))
```


This shows that the emotions were measured based on a visual analogue scale (VAS) from 0 to 100. For these analyses, we focus on the emotions *interest* and *sad*. Notice, that there are `r sum(mlvardata[, "interest"] < 0, na.rm = TRUE)` observations with negative scores on the variable *interest*. As this should not be the case, we further explore these observations. 

First, we create a subset of the data that only includes these observations and the variables *ID*, *interest*, and *sad*:

```{r}
mlvardata_minus0 <- mlvardata[mlvardata[, "interest"] < 0 & 
                                !is.na(mlvardata[, "interest"]), 
                              c("lifepak_id", "interest", "sad")]
```

The negative scores either -1 or -2 and come from `r nsub(mlvardata_minus0$lifepak_id)` subjects. The complete data of these subjects is stored in the following data.frame: 

```{r}
mlvardata_neg <- mlvardata[mlvardata$lifepak_id %in% 
                             unique(mlvardata_minus0$lifepak_id), 
                           c("lifepak_id", "interest", "sad")]
```

Moreover, the observed time series of these `r nsub(mlvardata_minus0$lifepak_id)` subjects are presented in the following Figure:

```{r tsminus0, fig.cap = paste0("Time series of the variable 'interest' of the ", nsub(mlvardata_minus0$lifepak_id), " subjects with scores lower than 0.")}
par(mfrow = c(2, 1), mar = c(4, 4, 1, 2) + 0.1)

plot.ts(mlvardata_neg$interest[mlvardata_neg$lifepak_id == 
                                 unique(mlvardata_minus0$lifepak_id)[1]],
        ylab = "Interest", ylim = c(-5, 100),
        xlab = "", xlim = c(0, 110), las = 1)
mtext(paste0("ID = ", unique(mlvardata_minus0$lifepak_id)[1]), 3, at = 100)
plot.ts(mlvardata_neg$interest[mlvardata_neg$lifepak_id ==
                                 unique(mlvardata_minus0$lifepak_id)[2]],
        ylab = "Interest", ylim = c(-5, 100),
        xlab = "Beep", xlim = c(0, 110), las = 1)
mtext(paste0("ID = ", unique(mlvardata_minus0$lifepak_id)[2]), 3, at = 100)

```

As the data from these subjects is not reliable, we decide to exclude them from the analyses. Thus, we create another data.frame without their data.

```{r}
mlvardata02 <- mlvardata[!(mlvardata$lifepak_id %in% 
                             unique(mlvardata_minus0$lifepak_id)), ]
```

```{r, echo = FALSE}
rm(mlvardata_minus0, mlvardata_neg)
```

Now, we also create two subsets of the data. The first subset includes the whole sample and we use the ML-VAR to analyze this data. In this case, we also exclude subjects with less than 5 observations. The second subset includes subjects that complied with at least 60 observations on both variables (*interest* and *sad*). We use the VAR model to analyze the data of each individual on this dataset.

We create the first subset as follows:

```{r}
# Get compliance per subject for 'interest'
comp_interest <- calc.nomiss(interest, lifepak_id, mlvardata02)

# Get IDs of subjects with less than 5 responses
id_exclude <- as.numeric(names(which(comp_interest < 5)))

# Exclude subjects with less than 5 responses
data_mlvar <- mlvardata02[!(mlvardata02$lifepak_id %in% id_exclude), ]
```

For the second subset, we first create a variable that indicates if the person has a valid scores on both variables *interest* and *sad*, then, based on this new variable, we select the individuals with more than 60 observations. 

```{r}
# Create indicator variable of valid scores on 'interest' and 'sad'
mlvardata02$ind_nomiss <- ifelse(is.na(mlvardata02$interest) &
                                   is.na(mlvardata02$sad), NA, 1)

# Get compliance on both variables per person
comp_both <- calc.nomiss(ind_nomiss, lifepak_id, mlvardata02)

# Get IDs of subjects with 60 or more responses on both variables
id_include <- as.numeric(names(which(comp_both >= 60)))

# Exclude subjects with less than 60 responses on both variables
data_var <- mlvardata02[mlvardata02$lifepak_id %in% id_include, ]

# Remove indicator variable in final subset
data_var <- data_var[, 1:14]

```

```{r, echo = FALSE}
rm(mlvardata, mlvardata02, comp_both, comp_interest, id_exclude, id_include)
```

## Sample's Descriptives

After cleaning the data, we get that ML-VAR data includes responses from `r nsub(data_mlvar$lifepak_id)` participants. These participants replied between `r min(calc.nomiss(interest, lifepak_id, data_mlvar))` and `r max(calc.nomiss(interest, lifepak_id, data_mlvar))` beeps. In particular, the distribution of the compliance is presented in Figure \@ref(fig:compliance):

```{r compliance, fig.cap = "Compliance on variable 'interest'"}
hist(calc.nomiss(interest, lifepak_id, data_mlvar),
     ylim = c(0, 8),
     xlim = c(0, 120),
     xlab = "Number of complied beeps",
     las = 1,
     breaks = 40,
     main = "")

```

We can also see the distribution of the missing values on both variables in the following Figures:

```{r heatmapinterest, fig.cap = "Missing values visualization of the variable 'interest'"}
tmp <- reshape(na.omit(data_mlvar[, c(1, 2, 12)]), 
               direction = "wide", 
               idvar = "lifepak_id", 
               timevar = "response_no")
naniar::vis_miss(tmp[, -1], show_perc_col = FALSE)
rm(tmp)
```

```{r heatmapsad, fig.cap = "Missing values visualization of the variable 'sad'"}
tmp <- reshape(na.omit(data_mlvar[, c(1, 2, 14)]), 
               direction = "wide", 
               idvar = "lifepak_id", 
               timevar = "response_no")
naniar::vis_miss(tmp[, -1], show_perc_col = FALSE)
rm(tmp)
```

Next, Figure @ref(fig:hist) presents the overall distribution of each variable of interest across the sample:

```{r hist, fig.cap="Overall distribution of the variables 'interest' and 'sad'"}
par(mfrow = c(1, 2))
hist(data_mlvar$interest, 
     main = "",
     las = 1,
     ylim = c(0, 2000),
     xlab = "Interest",
     breaks = 40)
hist(data_mlvar$sad,
     main = "",
     las = 1,
     ylim = c(0, 2000),
     xlab = "Sad",
     breaks = 40)
```

The distributions showed very high peaks at 0, 50 and 100. In particular the frecuency of each of these responses can be checked as follows:

```{r}
sum(data_mlvar$sad == 0, na.rm = TRUE)
sum(data_mlvar$sad == 50, na.rm = TRUE)
sum(data_mlvar$sad == 100, na.rm = TRUE)

sum(data_mlvar$interest == 0, na.rm = TRUE)
sum(data_mlvar$interest == 50, na.rm = TRUE)
sum(data_mlvar$interest == 100, na.rm = TRUE)
```

## Individuals' Descriptives

For the VAR analyses, the sample got reduced to `r nsub(data_var$lifepak_id)` subjects. These individuals replied to at least 60 beeps on both variables of interest. Similarly as presented before, the distribution of the missing values is presented in Figures \@ref(fig:heatmapinterest2) and \@ref(fig:heatmapsad2).

```{r heatmapinterest2, fig.cap = "Missing values visualization of the variable 'interest', VAR subset."}
tmp <- reshape(na.omit(data_var[, c(1, 2, 12)]), 
               direction = "wide", 
               idvar = "lifepak_id", 
               timevar = "response_no")
naniar::vis_miss(tmp[, -1], show_perc_col = FALSE)
rm(tmp)
```

```{r heatmapsad2, fig.cap = "Missing values visualization of the variable 'sad', VAR subset"}
tmp <- reshape(na.omit(data_var[, c(1, 2, 14)]), 
               direction = "wide", 
               idvar = "lifepak_id", 
               timevar = "response_no")
naniar::vis_miss(tmp[, -1], show_perc_col = FALSE)
rm(tmp)
```

Next, we look at the mean and standard deviation of each of the variables per person. To computes these descriptive, we use the following code:

```{r}
mean_interest <- tapply(data_var$interest, data_var$lifepak_id, mean, na.rm = TRUE) 
mean_sad      <- tapply(data_var$sad, data_var$lifepak_id, mean, na.rm = TRUE) 

sd_interest <- tapply(data_var$interest, data_var$lifepak_id, sd, na.rm = TRUE) 
sd_sad      <- tapply(data_var$sad, data_var$lifepak_id, sd, na.rm = TRUE) 
```

```{r meanscat, fig.cap = "Scatterplot of intraindividual means of 'interest' and 'sad'."}
plot(mean_interest, mean_sad)
```


```{r sdscat, fig.cap = "Scatterplot of intraindividual sd of 'interest' and 'sad'."}
plot(sd_interest, sd_sad)
abline(h = 9.5, col = gray(0.5))
abline(v = 9.5, col = gray(0.5))
```

```{r}
ids <- unique(data_var$lifepak_id)
pdf("TimeSeries.pdf")
for (i in 1:length(ids)) {
  plot.ts(data_var[data_var$lifepak_id == ids[i], c("interest", "sad")],
          main = paste0("Subject ID = ", ids[i]), 
          ylab = "Emotion Scores",
          plot.type = "single", ylim = c(0, 100), 
          col = gray(c(0.1, 0.5)), las = 1, lwd = 1.5)
  mtext(paste0("Interest: Mean = ", 
               round(mean(data_var[data_var$lifepak_id == ids[i], "interest"], 
                          na.rm = TRUE), 2), ", sd =", 
               round(sd(data_var[data_var$lifepak_id == ids[i], "interest"], 
                        na.rm = TRUE), 2)), 
        side = 3, at = 1, line= 0.8, adj = 0, cex = 0.7)
  mtext(paste0("Sad: Mean = ", 
               round(mean(data_var[data_var$lifepak_id == ids[i], "sad"], 
                          na.rm = TRUE), 2), ", sd =", 
               round(sd(data_var[data_var$lifepak_id == ids[i], "sad"], 
                        na.rm = TRUE), 2)), 
        side = 3, at = 1, adj = 0, cex = 0.7)
  legend("bottomright", c("Interest", "Sad"), 
         col = gray(c(0.1, 0.5)), lwd = 1.5, bg = "white")
}
rm(i)
dev.off()
```

Also, for the individual VAR analyses, we remove participants with standard deviation lower than 9.5 on either of the two variables:

```{r}
sd_lower <- ifelse(sd_interest < 9.5 | sd_sad < 9.5, TRUE, FALSE)
sd_exclude <- as.numeric(names(which(sd_lower)))

data_var <- data_var[!(data_var$lifepak_id %in% sd_exclude), ]
ids <- unique(data_var$lifepak_id)
```



```{r}
correlations <- rep(NA, length(ids))

for (i in 1:length(ids)) {
  correlations[i] <- cor(data_var[data_var$lifepak_id == ids[i], "interest"],
                         data_var[data_var$lifepak_id == ids[i], "sad"], 
                         use = "complete.obs")
}

```

```{r}
hist(correlations, breaks = 15)
```


Fit lm with trend (check kpss) and if it is significant plot time series of those individuals

check if there is enough variance... what is considered enough variance? sd of minimum 10% of the scale... meaning minimum sd must be 10.

In ML VAR try with and without sd lower than 10 on both, in VAr only without sd lower than 10.

Do the analysis with time trend. Maybe with the actual time (depending how hard it is to turn that into reasonable numbers) otherwise with beep number.

Start running the analysis... how similar are the coefficients of VAR and ML-VAR? get centrality measures of the coefficients.




